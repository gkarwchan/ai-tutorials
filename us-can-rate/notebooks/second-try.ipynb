{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06da7504-3c22-4d90-90d1-7fc992ca03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e2e89-5651-4dd2-a306-790bbf798511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "newsOrgKey = os.getenv(\"NEWS_ORG_API_KEY\")\n",
    "newsapiclient = NewsApiClient(api_key=newsOrgKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e22ddf-f274-40d5-96a5-1409054b844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsAnalyzer:\n",
    "    \"\"\"Collects and analyzes political news related to US-Canada relations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize sentiment analyzer\n",
    "        try:\n",
    "            self.sentiment_analyzer = pipeline(\"sentiment-analysis\", \n",
    "                                             model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "        except:\n",
    "            print(\"Using TextBlob for sentiment analysis as backup\")\n",
    "            self.sentiment_analyzer = None\n",
    "    \n",
    "    def get_canada_us_news(self, days_back=30):\n",
    "        \"\"\"Fetch news related to Canada-US relations and tariffs\"\"\"\n",
    "        news_data = []\n",
    "        \n",
    "        # RSS feeds for Canadian and US political/economic news\n",
    "        feeds = [\n",
    "            'https://rss.cnn.com/rss/edition.rss',\n",
    "            'https://feeds.reuters.com/reuters/businessNews',\n",
    "            'https://www.cbc.ca/cmlink/rss-topstories',\n",
    "            'https://globalnews.ca/feed/',\n",
    "        ]\n",
    "        \n",
    "        keywords = ['canada', 'tariff', 'trade', 'usd', 'cad', 'dollar', 'trump', 'trudeau']\n",
    "        \n",
    "        for feed_url in feeds:\n",
    "            try:\n",
    "                feed = feedparser.parse(feed_url)\n",
    "                for entry in feed.entries[:20]:  # Limit to recent entries\n",
    "                    title = entry.title.lower()\n",
    "                    summary = getattr(entry, 'summary', '').lower()\n",
    "                    \n",
    "                    # Check if article contains relevant keywords\n",
    "                    if any(keyword in title or keyword in summary for keyword in keywords):\n",
    "                        news_data.append({\n",
    "                            'title': entry.title,\n",
    "                            'summary': getattr(entry, 'summary', ''),\n",
    "                            'published': getattr(entry, 'published', ''),\n",
    "                            'link': getattr(entry, 'link', ''),\n",
    "                            'source': feed_url\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching from {feed_url}: {e}\")\n",
    "        \n",
    "        return news_data\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of given text\"\"\"\n",
    "        if self.sentiment_analyzer:\n",
    "            try:\n",
    "                result = self.sentiment_analyzer(text[:512])  # Limit text length\n",
    "                return {\n",
    "                    'label': result[0]['label'],\n",
    "                    'score': result[0]['score']\n",
    "                }\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Fallback to TextBlob\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "        \n",
    "        if polarity > 0.1:\n",
    "            return {'label': 'POSITIVE', 'score': polarity}\n",
    "        elif polarity < -0.1:\n",
    "            return {'label': 'NEGATIVE', 'score': abs(polarity)}\n",
    "        else:\n",
    "            return {'label': 'NEUTRAL', 'score': abs(polarity)}\n",
    "    \n",
    "    def get_sentiment_scores(self, news_data):\n",
    "        \"\"\"Process news data and extract sentiment scores\"\"\"\n",
    "        sentiment_scores = []\n",
    "        \n",
    "        for article in news_data:\n",
    "            text = f\"{article['title']} {article['summary']}\"\n",
    "            sentiment = self.analyze_sentiment(text)\n",
    "            \n",
    "            sentiment_scores.append({\n",
    "                'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "                'title': article['title'],\n",
    "                'sentiment_label': sentiment['label'],\n",
    "                'sentiment_score': sentiment['score'],\n",
    "                'source': article['source']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf89854a-09d0-443a-be15-462551945231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExchangeRateCollector:\n",
    "    \"\"\"Collects historical USD/CAD exchange rate data\"\"\"\n",
    "    \n",
    "    def get_exchange_rate_data(self, start_date, end_date):\n",
    "        \"\"\"Fetch USD/CAD exchange rate data\"\"\"\n",
    "        try:\n",
    "            # Using Yahoo Finance for CAD=X (USD/CAD)\n",
    "            ticker = yf.Ticker(\"USDCAD=X\")\n",
    "            data = ticker.history(start=start_date, end=end_date)\n",
    "            \n",
    "            if data.empty:\n",
    "                # Alternative: use Federal Reserve Economic Data API or manual data\n",
    "                print(\"Yahoo Finance data not available, generating sample data...\")\n",
    "                dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "                \n",
    "                # Generate realistic USD/CAD data around 1.35 with some volatility\n",
    "                np.random.seed(42)\n",
    "                base_rate = 1.35\n",
    "                returns = np.random.normal(0, 0.01, len(dates))\n",
    "                prices = [base_rate]\n",
    "                \n",
    "                for ret in returns[1:]:\n",
    "                    prices.append(prices[-1] * (1 + ret))\n",
    "                \n",
    "                data = pd.DataFrame({\n",
    "                    'Open': prices,\n",
    "                    'High': [p * (1 + abs(np.random.normal(0, 0.005))) for p in prices],\n",
    "                    'Low': [p * (1 - abs(np.random.normal(0, 0.005))) for p in prices],\n",
    "                    'Close': prices,\n",
    "                    'Volume': np.random.randint(1000000, 5000000, len(dates))\n",
    "                }, index=dates)\n",
    "            \n",
    "            return data\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching exchange rate data: {e}\")\n",
    "            return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2852cb41-50e4-4b10-be50-44860f00a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    \"\"\"Creates features for machine learning model\"\"\"\n",
    "    \n",
    "    def create_technical_indicators(self, df):\n",
    "        \"\"\"Add technical indicators to the dataframe\"\"\"\n",
    "        # Moving averages\n",
    "        df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "        df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "        df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "        \n",
    "        # RSI (Relative Strength Index)\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['BB_upper'] = df['MA_20'] + (df['Close'].rolling(window=20).std() * 2)\n",
    "        df['BB_lower'] = df['MA_20'] - (df['Close'].rolling(window=20).std() * 2)\n",
    "        \n",
    "        # Volatility\n",
    "        df['Volatility'] = df['Close'].rolling(window=10).std()\n",
    "        \n",
    "        # Price changes\n",
    "        df['Price_Change'] = df['Close'].pct_change()\n",
    "        df['Price_Change_3d'] = df['Close'].pct_change(periods=3)\n",
    "        df['Price_Change_7d'] = df['Close'].pct_change(periods=7)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_sentiment_features(self, exchange_df, sentiment_df):\n",
    "        \"\"\"Add sentiment features to exchange rate data\"\"\"\n",
    "        # Aggregate daily sentiment scores\n",
    "        daily_sentiment = sentiment_df.groupby('date').agg({\n",
    "            'sentiment_score': ['mean', 'std', 'count']\n",
    "        }).flatten_cols()\n",
    "        \n",
    "        daily_sentiment.columns = ['sentiment_mean', 'sentiment_std', 'sentiment_count']\n",
    "        daily_sentiment.index = pd.to_datetime(daily_sentiment.index)\n",
    "        \n",
    "        # Merge with exchange rate data\n",
    "        exchange_df = exchange_df.join(daily_sentiment, how='left')\n",
    "        \n",
    "        # Forward fill missing sentiment data\n",
    "        exchange_df[['sentiment_mean', 'sentiment_std', 'sentiment_count']] = \\\n",
    "            exchange_df[['sentiment_mean', 'sentiment_std', 'sentiment_count']].fillna(method='ffill')\n",
    "        \n",
    "        return exchange_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139e1857-fc04-4d3c-b581-4096bee96c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExchangeRatePredictor:\n",
    "    \"\"\"Machine learning model for predicting exchange rates\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "            'Linear Regression': LinearRegression()\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        self.best_model = None\n",
    "        self.feature_columns = None\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for machine learning\"\"\"\n",
    "        feature_cols = [\n",
    "            'Open', 'High', 'Low', 'Volume',\n",
    "            'MA_5', 'MA_10', 'MA_20', 'RSI',\n",
    "            'BB_upper', 'BB_lower', 'Volatility',\n",
    "            'Price_Change', 'Price_Change_3d', 'Price_Change_7d',\n",
    "            'sentiment_mean', 'sentiment_std', 'sentiment_count'\n",
    "        ]\n",
    "        \n",
    "        # Remove rows with NaN values\n",
    "        df_clean = df[feature_cols + ['Close']].dropna()\n",
    "        \n",
    "        X = df_clean[feature_cols]\n",
    "        y = df_clean['Close']\n",
    "        \n",
    "        self.feature_columns = feature_cols\n",
    "        return X, y\n",
    "    \n",
    "    def train_models(self, X, y):\n",
    "        \"\"\"Train multiple models and select the best one\"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        best_score = float('-inf')\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            # Train model\n",
    "            if name == 'Linear Regression':\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Evaluate model\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            results[name] = {\n",
    "                'MAE': mae,\n",
    "                'RMSE': rmse,\n",
    "                'R2': r2,\n",
    "                'model': model\n",
    "            }\n",
    "            \n",
    "            print(f\"{name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "            \n",
    "            if r2 > best_score:\n",
    "                best_score = r2\n",
    "                self.best_model = model\n",
    "                self.best_model_name = name\n",
    "        \n",
    "        print(f\"\\nBest model: {self.best_model_name} with R2: {best_score:.4f}\")\n",
    "        return results\n",
    "    \n",
    "    def predict_future_rates(self, last_features, days=90):\n",
    "        \"\"\"Predict future exchange rates\"\"\"\n",
    "        predictions = []\n",
    "        current_features = last_features.copy()\n",
    "        \n",
    "        for day in range(days):\n",
    "            if self.best_model_name == 'Linear Regression':\n",
    "                features_scaled = self.scaler.transform([current_features])\n",
    "                pred = self.best_model.predict(features_scaled)[0]\n",
    "            else:\n",
    "                pred = self.best_model.predict([current_features])[0]\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            \n",
    "            # Update features for next prediction (simplified approach)\n",
    "            # In practice, you'd want more sophisticated feature updating\n",
    "            current_features[0] = pred  # Update 'Open' with predicted close\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a4234a-06c1-481f-a1d6-a71bd9ac20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline():\n",
    "    \"\"\"Execute the complete pipeline\"\"\"\n",
    "    print(\"\\n=== Step 1: Data Collection ===\")\n",
    "    \n",
    "    # Initialize components\n",
    "    news_analyzer = NewsAnalyzer()\n",
    "    exchange_collector = ExchangeRateCollector()\n",
    "    feature_engineer = FeatureEngineering()\n",
    "    predictor = ExchangeRatePredictor()\n",
    "    \n",
    "    # Collect news data\n",
    "    print(\"Collecting news data...\")\n",
    "    news_data = news_analyzer.get_canada_us_news()\n",
    "    print(f\"Collected {len(news_data)} relevant news articles\")\n",
    "    \n",
    "    # Analyze sentiment\n",
    "    print(\"Analyzing sentiment...\")\n",
    "    sentiment_df = news_analyzer.get_sentiment_scores(news_data)\n",
    "    print(f\"Processed sentiment for {len(sentiment_df)} articles\")\n",
    "    \n",
    "    # Display sentiment summary\n",
    "    if not sentiment_df.empty:\n",
    "        sentiment_summary = sentiment_df['sentiment_label'].value_counts()\n",
    "        print(\"Sentiment Distribution:\")\n",
    "        print(sentiment_summary)\n",
    "    \n",
    "    # Collect exchange rate data\n",
    "    print(\"\\n=== Step 2: Exchange Rate Data Collection ===\")\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365)  # 1 year of data\n",
    "    \n",
    "    exchange_df = exchange_collector.get_exchange_rate_data(start_date, end_date)\n",
    "    print(f\"Collected {len(exchange_df)} days of exchange rate data\")\n",
    "    \n",
    "    # Feature engineering\n",
    "    print(\"\\n=== Step 3: Feature Engineering ===\")\n",
    "    exchange_df = feature_engineer.create_technical_indicators(exchange_df)\n",
    "    \n",
    "    if not sentiment_df.empty:\n",
    "        exchange_df = feature_engineer.add_sentiment_features(exchange_df, sentiment_df)\n",
    "    else:\n",
    "        # Add dummy sentiment features if no news data available\n",
    "        exchange_df['sentiment_mean'] = 0\n",
    "        exchange_df['sentiment_std'] = 0\n",
    "        exchange_df['sentiment_count'] = 0\n",
    "    \n",
    "    print(\"Features created successfully\")\n",
    "    \n",
    "    # Prepare data for ML\n",
    "    print(\"\\n=== Step 4: Machine Learning Training ===\")\n",
    "    X, y = predictor.prepare_features(exchange_df)\n",
    "    print(f\"Training data shape: {X.shape}\")\n",
    "    \n",
    "    # Train models\n",
    "    results = predictor.train_models(X, y)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"\\n=== Step 5: Future Predictions ===\")\n",
    "    last_features = X.iloc[-1].values\n",
    "    future_rates = predictor.predict_future_rates(last_features, days=90)\n",
    "    \n",
    "    # Create prediction dates\n",
    "    last_date = exchange_df.index[-1]\n",
    "    future_dates = [last_date + timedelta(days=i+1) for i in range(90)]\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Results Summary ===\")\n",
    "    current_rate = exchange_df['Close'].iloc[-1]\n",
    "    avg_future_rate = np.mean(future_rates)\n",
    "    \n",
    "    print(f\"Current USD/CAD rate: {current_rate:.4f}\")\n",
    "    print(f\"Predicted average rate (next 3 months): {avg_future_rate:.4f}\")\n",
    "    \n",
    "    # Find best conversion opportunities\n",
    "    min_rate_idx = np.argmin(future_rates)\n",
    "    max_rate_idx = np.argmax(future_rates)\n",
    "    \n",
    "    print(f\"\\nBest time to convert USD to CAD (lowest rate):\")\n",
    "    print(f\"Date: {future_dates[min_rate_idx].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Predicted rate: {future_rates[min_rate_idx]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nWorst time to convert USD to CAD (highest rate):\")\n",
    "    print(f\"Date: {future_dates[max_rate_idx].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Predicted rate: {future_rates[max_rate_idx]:.4f}\")\n",
    "    \n",
    "    # Plotting\n",
    "    print(\"\\n=== Generating Visualizations ===\")\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Historical rates and predictions\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(exchange_df.index[-60:], exchange_df['Close'].iloc[-60:], \n",
    "             label='Historical Rates', color='blue')\n",
    "    plt.plot(future_dates, future_rates, \n",
    "             label='Predicted Rates', color='red', linestyle='--')\n",
    "    plt.title('USD/CAD Exchange Rate Prediction')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Exchange Rate')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 2: Sentiment over time (if available)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    if not sentiment_df.empty:\n",
    "        sentiment_counts = sentiment_df['sentiment_label'].value_counts()\n",
    "        plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "        plt.title('News Sentiment Distribution')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No sentiment data available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('News Sentiment Distribution')\n",
    "    \n",
    "    # Plot 3: Feature importance (for tree-based models)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if hasattr(predictor.best_model, 'feature_importances_'):\n",
    "        importances = predictor.best_model.feature_importances_\n",
    "        features = predictor.feature_columns\n",
    "        indices = np.argsort(importances)[::-1][:10]\n",
    "        \n",
    "        plt.bar(range(len(indices)), importances[indices])\n",
    "        plt.title('Top 10 Feature Importances')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.xticks(range(len(indices)), [features[i] for i in indices], rotation=45)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Feature importance not available\\nfor this model type', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Feature Importance')\n",
    "    \n",
    "    # Plot 4: Prediction confidence intervals\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Create confidence intervals (simplified approach)\n",
    "    std_dev = np.std(future_rates)\n",
    "    upper_bound = np.array(future_rates) + 2 * std_dev\n",
    "    lower_bound = np.array(future_rates) - 2 * std_dev\n",
    "    \n",
    "    plt.fill_between(future_dates, lower_bound, upper_bound, alpha=0.3, color='gray')\n",
    "    plt.plot(future_dates, future_rates, color='red', linewidth=2)\n",
    "    plt.title('Prediction with Confidence Intervals')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Exchange Rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'current_rate': current_rate,\n",
    "        'future_predictions': list(zip(future_dates, future_rates)),\n",
    "        'best_conversion_date': future_dates[min_rate_idx],\n",
    "        'best_conversion_rate': future_rates[min_rate_idx],\n",
    "        'sentiment_summary': sentiment_df['sentiment_label'].value_counts().to_dict() if not sentiment_df.empty else {},\n",
    "        'model_performance': results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691b86b9-e4b3-4bce-9178-c0ef94dd8b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1: Data Collection ===\n",
      "Using TextBlob for sentiment analysis as backup\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmain_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m exchange_collector = ExchangeRateCollector()\n\u001b[32m      8\u001b[39m feature_engineer = FeatureEngineering()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m predictor = \u001b[43mExchangeRatePredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Collect news data\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCollecting news data...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mExchangeRatePredictor.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.models = {\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mRandomForestRegressor\u001b[49m(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m      7\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m: GradientBoostingRegressor(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mLinear Regression\u001b[39m\u001b[33m'\u001b[39m: LinearRegression()\n\u001b[32m      9\u001b[39m     }\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mself\u001b[39m.scaler = StandardScaler()\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mself\u001b[39m.best_model = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "results = main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad8596-be4a-47e9-b209-0e815701ca10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
